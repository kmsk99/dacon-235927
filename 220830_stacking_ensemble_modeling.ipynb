{"cells":[{"cell_type":"markdown","source":["# 1 코드 실행환경"],"metadata":{"id":"EvPGVxikBYwV"}},{"cell_type":"markdown","source":["\bGoogle Colab\n","\n","런타임 유형 : GPU\n","\n","Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n","\n","Ubuntu 18.04.6 LTS\n","\n","Python 3.7.13\n","\n","GPU : NVIDIA-SMI 460.32.03 Driver Version: 460.32.03 CUDA Version: 11.2 Tesla T4"],"metadata":{"id":"FIH__iJmA_nJ"}},{"cell_type":"code","source":["import platform\n","platform.platform()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1-XKmwhQBAaN","executionInfo":{"status":"ok","timestamp":1661867410166,"user_tz":-540,"elapsed":10,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"19f67889-e612-42d1-acef-5d19d0d9e725"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["!cat /etc/issue.net"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lG1abR2jBEoX","executionInfo":{"status":"ok","timestamp":1661867426658,"user_tz":-540,"elapsed":8,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"a9d4e502-0a86-4512-a459-35322462e2a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ubuntu 18.04.6 LTS\n"]}]},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fs92HqYBF64","executionInfo":{"status":"ok","timestamp":1661867427124,"user_tz":-540,"elapsed":6,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"3194ab20-1f8e-42e8-c603-457c7bce9c21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.13\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dttGTjpZBHdc","executionInfo":{"status":"ok","timestamp":1661867427476,"user_tz":-540,"elapsed":19,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"276cd5cc-51f9-41f2-e493-0a3c45a6e0a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Aug 30 13:50:27 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["## 1.1 데이터 입/출력 경로 지정"],"metadata":{"id":"YHujaUSIBeLg"}},{"cell_type":"markdown","source":["구글 코랩 사용시 구글 드라이브 연결 사용\n","\n","로컬 환경 사용시 로컬 환경 경로로 설정"],"metadata":{"id":"w8DUhEEQBSBE"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vy_T0fS0-I6M","outputId":"0d6a6ca4-95f2-40f7-d20d-f44ef4184458","executionInfo":{"status":"ok","timestamp":1661925418523,"user_tz":-540,"elapsed":17439,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["#구글 드라이브 연결\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive/')\n","\n","#코랩 환경 경로 설정 \n","DATA_PATH = '/content/gdrive/MyDrive/dacon-235927-kops/data/'"]},{"cell_type":"code","source":["# 로컬 환경 경로 설정\n","DATA_PATH = '/data/'"],"metadata":{"id":"DVI76WUcBNG_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_y_YsWDK-mpi"},"source":["## 1.2 필요 라이브러리 설치"]},{"cell_type":"code","source":["# Optuna 설치\n","!pip install --quiet --no-cache-dir git+https://github.com/optuna/optuna\n","\n","# Catboost 설치\n","!pip install --quiet catboost\n","\n","# XGB GPU 버전 설치\n","!pip uninstall --quiet -y xgboost\n","!pip install --quiet xgboost\n","\n","# LGBM GPU 버전 설치\n","! git clone --recursive https://github.com/Microsoft/LightGBM\n","! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Q461MbGBViW","executionInfo":{"status":"ok","timestamp":1661925636434,"user_tz":-540,"elapsed":216749,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"790a9157-36c3-4def-ff0e-05fd0268c354"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 209 kB 8.5 MB/s \n","\u001b[K     |████████████████████████████████| 81 kB 72.7 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 76.5 MB/s \n","\u001b[K     |████████████████████████████████| 49 kB 66.9 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 83.9 MB/s \n","\u001b[K     |████████████████████████████████| 147 kB 75.7 MB/s \n","\u001b[?25h  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 76.6 MB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 255.9 MB 48 kB/s \n","\u001b[?25hCloning into 'LightGBM'...\n","remote: Enumerating objects: 27471, done.\u001b[K\n","remote: Counting objects: 100% (27470/27470), done.\u001b[K\n","remote: Compressing objects: 100% (6269/6269), done.\u001b[K\n","remote: Total 27471 (delta 20416), reused 27227 (delta 20291), pack-reused 1\n","Receiving objects: 100% (27471/27471), 19.48 MiB | 28.17 MiB/s, done.\n","Resolving deltas: 100% (20416/20416), done.\n","Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n","Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n","Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n","Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n","Cloning into '/content/LightGBM/external_libs/compute'...\n","remote: Enumerating objects: 21733, done.        \n","remote: Counting objects: 100% (5/5), done.        \n","remote: Compressing objects: 100% (4/4), done.        \n","remote: Total 21733 (delta 1), reused 3 (delta 1), pack-reused 21728        \n","Receiving objects: 100% (21733/21733), 8.51 MiB | 28.95 MiB/s, done.\n","Resolving deltas: 100% (17567/17567), done.\n","Cloning into '/content/LightGBM/external_libs/eigen'...\n","remote: Enumerating objects: 116676, done.        \n","remote: Counting objects: 100% (1746/1746), done.        \n","remote: Compressing objects: 100% (627/627), done.        \n","remote: Total 116676 (delta 1188), reused 1610 (delta 1119), pack-reused 114930        \n","Receiving objects: 100% (116676/116676), 103.49 MiB | 27.37 MiB/s, done.\n","Resolving deltas: 100% (95994/95994), done.\n","Cloning into '/content/LightGBM/external_libs/fast_double_parser'...\n","remote: Enumerating objects: 726, done.        \n","remote: Counting objects: 100% (125/125), done.        \n","remote: Compressing objects: 100% (33/33), done.        \n","remote: Total 726 (delta 98), reused 97 (delta 88), pack-reused 601        \n","Receiving objects: 100% (726/726), 821.50 KiB | 15.21 MiB/s, done.\n","Resolving deltas: 100% (369/369), done.\n","Cloning into '/content/LightGBM/external_libs/fmt'...\n","remote: Enumerating objects: 30377, done.        \n","remote: Total 30377 (delta 0), reused 0 (delta 0), pack-reused 30377        \n","Receiving objects: 100% (30377/30377), 14.25 MiB | 16.58 MiB/s, done.\n","Resolving deltas: 100% (20528/20528), done.\n","Submodule path 'external_libs/compute': checked out '36350b7de849300bd3d72a05d8bf890ca405a014'\n","Submodule path 'external_libs/eigen': checked out '3147391d946bb4b6c68edd901f2add6ac1f31f8c'\n","Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n","Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n","Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n","Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n","remote: Enumerating objects: 18011, done.        \n","remote: Counting objects: 100% (188/188), done.        \n","remote: Compressing objects: 100% (130/130), done.        \n","remote: Total 18011 (delta 60), reused 167 (delta 56), pack-reused 17823        \n","Receiving objects: 100% (18011/18011), 11.36 MiB | 16.75 MiB/s, done.\n","Resolving deltas: 100% (13938/13938), done.\n","Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n","remote: Enumerating objects: 1348, done.        \n","remote: Counting objects: 100% (192/192), done.        \n","remote: Compressing objects: 100% (99/99), done.        \n","remote: Total 1348 (delta 105), reused 157 (delta 86), pack-reused 1156        \n","Receiving objects: 100% (1348/1348), 7.15 MiB | 18.04 MiB/s, done.\n","Resolving deltas: 100% (877/877), done.\n","Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n","Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n","Submodule path 'external_libs/fmt': checked out 'b6f4ceaed0a0a24ccf575fab6c56dd50ccf6f1a9'\n","-- The C compiler identification is GNU 7.5.0\n","-- The CXX compiler identification is GNU 7.5.0\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Check for working C compiler: /usr/bin/cc - skipped\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Check for working CXX compiler: /usr/bin/c++ - skipped\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n","-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n","-- Found OpenMP: TRUE (found version \"4.5\")  \n","-- Looking for CL_VERSION_2_2\n","-- Looking for CL_VERSION_2_2 - found\n","-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n","-- OpenCL include directory: /usr/include\n","-- Found Boost: /usr/include (found suitable version \"1.65.1\", minimum required is \"1.56.0\") found components: filesystem system \n","-- Performing Test MM_PREFETCH\n","-- Performing Test MM_PREFETCH - Success\n","-- Using _mm_prefetch\n","-- Performing Test MM_MALLOC\n","-- Performing Test MM_MALLOC - Success\n","-- Using _mm_malloc\n","-- Configuring done\n","-- Generating done\n","-- Build files have been written to: /content/LightGBM/build\n","[  2%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_capi_objs.dir/src/c_api.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/boosting.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/cuda/cuda_score_updater.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/cuda/cuda_utils.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/bin.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/config.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/config_auto.cpp.o\u001b[0m\n","[ 22%] Built target lightgbm_capi_objs\n","[ 25%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_column_data.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_metadata.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_row_data.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/cuda/cuda_tree.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/dataset_loader.cpp.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/file_io.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/json11.cpp.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/metadata.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/parser.cpp.o\u001b[0m\n","[ 45%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/train_share_states.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/io/tree.cpp.o\u001b[0m\n","[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/metric/metric.cpp.o\u001b[0m\n","[ 54%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/linker_topo.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/linkers_socket.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/network/network.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/objective/cuda/cuda_binary_objective.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/objective/objective_function.cpp.o\u001b[0m\n","[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_best_split_finder.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_data_partition.cpp.o\u001b[0m\n","[ 70%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_histogram_constructor.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_leaf_splits.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda/cuda_single_gpu_tree_learner.cpp.o\u001b[0m\n","[ 77%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n","[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n","[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n","[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n","[ 87%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n","[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n","[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm_objs.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n","[ 91%] Built target lightgbm_objs\n","[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n","[ 95%] \u001b[32m\u001b[1mLinking CXX shared library ../lib_lightgbm.so\u001b[0m\n","[ 97%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n","[ 97%] Built target _lightgbm\n","[100%] \u001b[32m\u001b[1mLinking CXX executable ../lightgbm\u001b[0m\n","[100%] Built target lightgbm\n","running install\n","running build\n","running build_py\n","INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n","INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n","creating build\n","creating build/lib\n","creating build/lib/lightgbm\n","copying lightgbm/basic.py -> build/lib/lightgbm\n","copying lightgbm/callback.py -> build/lib/lightgbm\n","copying lightgbm/libpath.py -> build/lib/lightgbm\n","copying lightgbm/dask.py -> build/lib/lightgbm\n","copying lightgbm/compat.py -> build/lib/lightgbm\n","copying lightgbm/plotting.py -> build/lib/lightgbm\n","copying lightgbm/engine.py -> build/lib/lightgbm\n","copying lightgbm/sklearn.py -> build/lib/lightgbm\n","copying lightgbm/__init__.py -> build/lib/lightgbm\n","running egg_info\n","creating lightgbm.egg-info\n","writing lightgbm.egg-info/PKG-INFO\n","writing dependency_links to lightgbm.egg-info/dependency_links.txt\n","writing requirements to lightgbm.egg-info/requires.txt\n","writing top-level names to lightgbm.egg-info/top_level.txt\n","writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n","reading manifest template 'MANIFEST.in'\n","no previously-included directories found matching 'build'\n","warning: no files found matching 'LICENSE'\n","warning: no files found matching '*.txt'\n","warning: no files found matching '*.so' under directory 'lightgbm'\n","warning: no files found matching 'compile/CMakeLists.txt'\n","warning: no files found matching 'compile/cmake/IntegratedOpenCL.cmake'\n","warning: no files found matching '*.so' under directory 'compile'\n","warning: no files found matching '*.dll' under directory 'compile/Release'\n","warning: no files found matching 'compile/external_libs/compute/CMakeLists.txt'\n","warning: no files found matching '*' under directory 'compile/external_libs/compute/cmake'\n","warning: no files found matching '*' under directory 'compile/external_libs/compute/include'\n","warning: no files found matching '*' under directory 'compile/external_libs/compute/meta'\n","warning: no files found matching 'compile/external_libs/eigen/CMakeLists.txt'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/Cholesky'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/Core'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/Dense'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/Eigenvalues'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/Geometry'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/Householder'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/Jacobi'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/LU'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/QR'\n","warning: no files found matching 'compile/external_libs/eigen/Eigen/SVD'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Cholesky'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Core'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Eigenvalues'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Geometry'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Householder'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Jacobi'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/LU'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/misc'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/plugins'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/QR'\n","warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/SVD'\n","warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n","warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n","warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n","warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n","warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n","warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n","warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n","warning: no files found matching '*' under directory 'compile/include'\n","warning: no files found matching '*' under directory 'compile/src'\n","warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n","warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n","warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n","warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n","warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n","writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n","copying lightgbm/VERSION.txt -> build/lib/lightgbm\n","running install_lib\n","copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/dask.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","INFO:LightGBM:Installing lib_lightgbm from: ['/content/LightGBM/lib_lightgbm.so']\n","copying /content/LightGBM/lib_lightgbm.so -> /usr/local/lib/python3.7/dist-packages/lightgbm\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/basic.py to basic.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/callback.py to callback.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/libpath.py to libpath.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/dask.py to dask.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/compat.py to compat.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/plotting.py to plotting.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py to engine.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py to sklearn.cpython-37.pyc\n","byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/__init__.py to __init__.cpython-37.pyc\n","running install_egg_info\n","Copying lightgbm.egg-info to /usr/local/lib/python3.7/dist-packages/lightgbm-3.3.2.99-py3.7.egg-info\n","running install_scripts\n"]}]},{"cell_type":"markdown","metadata":{"id":"bM-vQh3PCP4S"},"source":["## 1.3 라이브러리 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXWzz_ia-iKJ"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression\n","from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n","\n","import xgboost as xgb\n","import lightgbm as lgb\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","\n","import optuna \n","from optuna import Trial, visualization\n","\n","import joblib\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","source":["## 1.4 시드 고정"],"metadata":{"id":"vc1EeKkIBpCu"}},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","seed_everything(42) \n","SEED = 42"],"metadata":{"id":"c1uA7JH5do9P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HW6k0i0tkKTw"},"source":["# 2 데이터 전처리"]},{"cell_type":"code","source":["# 데이터 로드\n","train = pd.read_csv(DATA_PATH + 'train.csv')\n","\n","# X Y 데이터 분리\n","X_train = train.filter(regex='X') # Input : X Featrue\n","Y_train = train.filter(regex='Y') # Output : Y Feature"],"metadata":{"id":"bwJWS0SFdksb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjqEH6CKsQKs"},"outputs":[],"source":["# 결과에 영향 낮은 인자 제거\n","X_train = X_train.drop(['X_04', 'X_23', 'X_47', 'X_48', 'X_10', 'X_11', 'X_02'], axis=1)"]},{"cell_type":"code","source":["# X_33 이상치 제거\n","\n","drop_idx = X_train.loc[X_train['X_33'] > 6 ].index\n","\n","X_train = X_train.drop(drop_idx, axis = 0)\n","Y_train = Y_train.drop(drop_idx, axis = 0)\n","\n","X_train = X_train.reset_index(drop = True)\n","Y_train = Y_train.reset_index(drop = True)"],"metadata":{"id":"Zg6yTdeqFSZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PCA 클래스 설정\n","class PCA_transform:\n","\n","  def __init__(self):\n","    self.cols_list = []\n","    self.pca_list = []\n","    self.n_pca_list = []\n","    self.size = 0\n","  \n","  # PCA 클래스의 학습 및 input 값 변환\n","  def fit_transform(self, X_input, col, n_pca):\n","\n","    X_pca = X_input[col]\n","\n","    # n차원으로 차원 축소, target 정보는 제외\n","    pca = PCA(n_components = n_pca)\n","\n","    # PCA 학습\n","    pca.fit(X_pca)\n","\n","    # PCA transform 후 데이터프레임으로 자료형 변경\n","    X_pca = pca.transform(X_pca)\n","    X_pca = pd.DataFrame(X_pca, columns = self.naming(n_pca))\n","\n","    X_input = pd.concat([X_input, X_pca], axis = 1)\n","    X_input = X_input.drop(col, axis = 1)\n","\n","    self.cols_list.append(col)\n","    self.pca_list.append(pca)\n","    self.n_pca_list.append(n_pca)\n","    self.size += 1\n","\n","    return X_input\n","\n","  # 학습된 PCA 값으로 transform\n","  def transform(self, X_input):\n","    for idx in range(self.size):\n","      X_input = self._idx_transform(X_input, idx)\n","    \n","    return X_input\n","\n","  # n번째 PCA 변환\n","  def _idx_transform(self, X_input, idx):\n","    X_pca = X_input[self.cols_list[idx]]\n","\n","    # pca transform 후 데이터프레임으로 자료형 변경\n","    X_pca = self.pca_list[idx].transform(X_pca)\n","    X_pca = pd.DataFrame(X_pca, columns = self.naming(self.n_pca_list[idx], idx))\n","\n","    X_input = pd.concat([X_input, X_pca], axis = 1)\n","    X_input = X_input.drop(self.cols_list[idx], axis = 1)\n","\n","    return X_input\n","\n","  # PCA 된 컬럼 이름 규칙\n","  def naming(self, number, name = None):\n","    if (name is None):\n","      name = self.size\n","    names = []\n","    for idx in range(number):\n","      names.append(f'PCA_{str(name)}_{idx}')\n","    return names"],"metadata":{"id":"7Gx6b3dUFY4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optuna로 최적화된 PCA 파라미터 적용\n","pca_5 = PCA_transform()\n","X_train = pca_5.fit_transform(X_train, ['X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18'], 5)\n","X_train = pca_5.fit_transform(X_train, ['X_19', 'X_20', 'X_21', 'X_22'], 2)\n","X_train = pca_5.fit_transform(X_train, ['X_34', 'X_35', 'X_36', 'X_37'], 1)\n","X_train = pca_5.fit_transform(X_train, ['X_41', 'X_42', 'X_43', 'X_44', 'X_45'], 1)\n","X_train = pca_5.fit_transform(X_train, ['X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56'], 2)"],"metadata":{"id":"Mydg6d_HFl68"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 평가산식 정의"],"metadata":{"id":"T5gJCBmGn0hx"}},{"cell_type":"code","source":["def nrmse(y_val, y_pred):\n","  rmse = mean_squared_error(y_val, y_pred, squared=False)\n","  nrmse = rmse/np.mean(np.abs(y_val))\n","  return nrmse\n","\n","def lg_nrmse(y_val, y_pred):\n","    # 각 Y Feature별 NRMSE 총합\n","    # Y_01 ~ Y_08 까지 20% 가중치 부여\n","\n","    y_val = pd.DataFrame(y_val)\n","    y_pred = pd.DataFrame(y_pred)\n","\n","    all_nrmse = []\n","    for idx in range(0,14):\n","        all_nrmse.append(nrmse(y_val.iloc[:,idx], y_pred.iloc[:,idx]))\n","        \n","    score = 1.2 * np.sum(all_nrmse[:7]) + 1.0 * np.sum(all_nrmse[7:14])\n","    return score"],"metadata":{"id":"WPT1SxPZnvhQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4 모델링"],"metadata":{"id":"mYrK3lm9B9GV"}},{"cell_type":"markdown","metadata":{"id":"gQgOXbLlVXc_"},"source":["## 4.1 Cross-validation을 통해 학습하는 ML class"]},{"cell_type":"code","source":["class CV_ml_model:\n","  # 머신러닝 모델, X_train, Y_train을 인자로 받음\n","  def __init__(self, model, X_train, Y_train):\n","    self.model = model\n","    self.name = model().__class__.__name__\n","    self.train_preds = [None] * 14\n","    self.trained_models = [None] * 14\n","    self.test_preds = [None] * 14\n","    self.X_train = self.to_np(X_train)\n","    self.Y_train = self.to_np(Y_train)\n","\n","\n","  # 넘파이 변환\n","  def to_np(self, input):\n","    if (type(input) == pd.core.frame.DataFrame):\n","      return input.to_numpy()\n","    return input\n","\n","\n","  # 이름 재설정\n","  def set_name(self, name):\n","    self.name = name\n","\n","  \n","  # Y 하나에 대해 머신러닝 수행\n","  def y_fit(self, n_folds, y_idx, X_train = None, param = {}, save = False):\n","    # X_train 따로 설정하지 않을 시 최초 입력 데이터 적용\n","    if (X_train is None):\n","      X_train = self.X_train\n","\n","    # 이미 학습된 y_idx일시 학습 중지\n","    if (self.train_preds[y_idx] is not None):\n","      return\n","\n","    # n_folds 숫자 만큼 학습된 모델이 들어갈 리스트 생성\n","    trained_y_models = [None] * n_folds\n","\n","    # 예측 결과를 넣을 ndarray 생성\n","    train_fold_pred = np.zeros((X_train.shape[0], 1))\n","\n","    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train)):\n","      #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n","      X_tr = X_train[train_index]\n","      y_tr = self.Y_train[:,y_idx][train_index]\n","      X_val = X_train[valid_index]\n","\n","      # 폴드 세트 내부에서 만들어진 학습 데이터로 기반 모델의 학습 수행.\n","      trained_model = self.model(**param).fit(X_tr , y_tr)  \n","      # 폴드 세트 내부에서 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n","      train_fold_pred[valid_index, :] = trained_model.predict(X_val).reshape(-1,1)\n","      # 학습 완료된 모델 리스트 내에 저장\n","      trained_y_models[folder_counter] = trained_model\n","    \n","    # 예측 결과 class 내 저장\n","    self.train_preds[y_idx] = train_fold_pred\n","    # 학습 완료된 모델 class 내 저장\n","    self.trained_models[y_idx] = trained_y_models\n","\n","    # 학습 완료시 모델을 파일로 저장\n","    if (save):\n","      self.save()\n","\n","  \n","  # 모델 경량화\n","  def slim_y_fit(self, n_folds, y_idx, X_train = None, param = {}, save = False):\n","    # X_train 따로 설정하지 않을 시 최초 입력 데이터 적용\n","    if (X_train is None):\n","      X_train = self.X_train\n","\n","    # 이미 학습된 y_idx일시 학습 중지\n","    if (self.train_preds[y_idx] is not None):\n","      return\n","\n","    # 예측 결과를 넣을 ndarray 생성\n","    train_fold_pred = np.zeros((X_train.shape[0], 1))\n","\n","    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train)):\n","      #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n","      X_tr = X_train[train_index] \n","      y_tr = self.Y_train[:,y_idx][train_index] \n","      X_val = X_train[valid_index]  \n","\n","      #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n","      trained_model = self.model(**param).fit(X_tr , y_tr)  \n","      #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n","      train_fold_pred[valid_index, :] = trained_model.predict(X_val).reshape(-1,1)\n","    \n","    # 예측 결과 class 내 저장\n","    self.train_preds[y_idx] = train_fold_pred\n","    # 학습 데이터 전체로 모델 학습 후 학습 완료된 모델 class 내 저장\n","    self.trained_models[y_idx] = [self.model(**param).fit(X_train , self.Y_train[:,y_idx])]\n","\n","    # 학습 완료시 모델을 파일로 저장\n","    if (save):\n","      self.save()\n","  \n","\n","  # Y 하나에 대해 예측 수행\n","  def y_predict(self, X_test, y_idx):\n","    # 학습 완료된 모델 갯수 확인\n","    size = len(self.trained_models[y_idx])\n","    # 예측 결과를 넣을 ndarray 생성\n","    test_pred = np.zeros((X_test.shape[0], size))\n","\n","    # 학습 완료된 모델 갯수만큼 예측 수행 \n","    for counter in range(size):\n","      test_pred[:, counter] = self.trained_models[y_idx][counter].predict(X_test)\n","\n","    # 예측된 결과값에 대해 평균을 구함\n","    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n","\n","    # 예측된 결과값을 class 내 저장\n","    self.test_preds[y_idx] = test_pred_mean\n","\n","    return test_pred_mean\n","  \n","\n","  # 머신러닝 훈련 실행\n","  # 파라미터 직접 적용시 동일 파라미터가 전체 적용\n","  # 불러오기 적용시 개별 적용\n","  def fit(self, n_folds, use_params = False, params = None, save = False):\n","    print(self.name, 'Started')\n","\n","    # use_params이 참이고, params가 없을 시 class 이름으로 하이퍼파라미터 튜닝된 파라미터 불러오기\n","    if (use_params):\n","      if (params is None):\n","        params = self.load_params(self.name)\n","        print('Params Loaded!')\n","        for y_idx in range(14):\n","          print(y_idx, end= ' ')\n","          self.y_fit(n_folds, y_idx, None, params[y_idx], save)\n","\n","      # use_params이 참이고, params이 존재할 시 모델 전체에 동일 params 적용\n","      else:\n","        for y_idx in range(14):\n","          print(y_idx, end= ' ')\n","          self.y_fit(n_folds, y_idx, None, params, save)\n","    \n","    # 파라미터 미적용\n","    else:\n","      for y_idx in range(14):\n","        print(y_idx, end= ' ')\n","        self.y_fit(n_folds, y_idx, save = save)\n","    \n","    print(self.name, 'Trained!')\n","\n","\n","  # 머신러닝 훈련 실행\n","  # 모델 저장시 하나의 모델로 저장하여 모델 경량화\n","  def slim_fit(self, n_folds, use_params = False, params = None, save = False):\n","    print(self.name, 'Started')\n","\n","    # use_params이 참이고, params가 없을 시 class 이름으로 하이퍼파라미터 튜닝된 파라미터 불러오기\n","    if (use_params):\n","      if (params is None):\n","        params = self.load_params(self.name)\n","        print('Params Loaded!')\n","        for y_idx in range(14):\n","          print(y_idx, end= ' ')\n","          self.slim_y_fit(n_folds, y_idx, None, params[y_idx], save)\n","\n","      # use_params이 참이고, params이 존재할 시 모델 전체에 동일 params 적용\n","      else:\n","        for y_idx in range(14):\n","          print(y_idx, end= ' ')\n","          self.slim_y_fit(n_folds, y_idx, None, params, save)\n","    \n","    # 파라미터 미적용\n","    else:\n","      for y_idx in range(14):\n","        print(y_idx, end= ' ')\n","        self.slim_y_fit(n_folds, y_idx, save = save)\n","    \n","    print(self.name, 'Slim!')\n","\n","\n","  # 학습된 모델을 통해 예측\n","  def predict(self, X_test):\n","    for y_idx in range(14):\n","      self.y_predict(X_test, y_idx)\n","\n","    return np.hstack(self.test_preds)\n","\n","\n","  # 예측된 Y_train 결과 반환\n","  def get_train_preds(self):\n","    return np.hstack(self.train_preds)\n","\n","\n","  # 예측된 Y_test 결과 반환\n","  def get_test_preds(self):\n","    return np.hstack(self.test_preds)\n","\n","\n","  # nrmse 값 반환\n","  def nrmse(self, y_idx):\n","    rmse = mean_squared_error(self.Y_train[:,y_idx], self.train_preds[y_idx], squared=False)\n","    nrmse = rmse/np.mean(np.abs(self.Y_train[:,y_idx]))\n","    return nrmse\n","\n","\n","  # 모델의 Cross-validation 점수 반환\n","  def score(self):\n","    all_nrmse = [None] * 14\n","    for y_idx in range(14):\n","      all_nrmse[y_idx] = self.nrmse(y_idx)\n","\n","    score = 1.2 * np.sum(all_nrmse[:7]) + 1.0 * np.sum(all_nrmse[7:14])\n","    return score\n","  \n","\n","  # 모델을 현재 이름으로 저장\n","  def save(self):\n","    saved_data = self.model, self.name, self.train_preds, self.trained_models, self.test_preds\n","    try:\n","      os.mkdir(DATA_PATH + \"ML_model\")\n","    except:\n","      pass\n","    joblib.dump(saved_data, DATA_PATH + \"ML_model/saved_\" + self.name + \".pkl\")\n","    # print(self.name, 'Saved!')\n","\n","\n","  # 모델을 현재 이름 혹은 입력한 이름으로 불러오기\n","  def load(self, name = None):\n","    if (not name):\n","      name = self.name\n","    try:\n","      loaded_data = joblib.load(DATA_PATH + \"ML_model/saved_\" + name + \".pkl\")\n","      self.model, self.name, self.train_preds, self.trained_models, self.test_preds = loaded_data\n","      print(self.name, 'Loaded!')\n","\n","      # 학습 전체가 완료된 모델일시 참 반환, 학습이 남은 모델일시 거짓 반환\n","      if (self.trained_models[13] is None):\n","        return False\n","      else:\n","        return True\n","    except:\n","      print(self.name, 'didnt loaded')\n","      return False\n","\n","\n","  # 파라미터 불러오기\n","  def load_params(self, name):\n","    params = [None] * 14\n","    for y_idx in range(14):\n","      try:\n","        load_study = joblib.load(DATA_PATH + \"tune_param/\" + name + \"/tune_\" + str(y_idx) + \".pkl\")\n","        params[y_idx] = load_study.best_trial.params\n","      except:\n","        print(name, y_idx,'params didnt loaded')\n","\n","    return params"],"metadata":{"id":"b00vOTUbUfu9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 CV_ml_model을 확장한 Stacking ensemble을 위한 Meta Learning class"],"metadata":{"id":"q1NtAfdRCI1a"}},{"cell_type":"code","source":["class meta_ml_model(CV_ml_model):\n","  def __init__(self, model, X_train, Y_train):\n","    super().__init__(model, X_train, Y_train)\n","    self.ml_models = []\n","    self.trained = []\n","\n","  \n","  # 머신러닝 모델 추가\n","  # 훈련된 CV_ml_model을 받음\n","  def add_trained_ml_models(self, *models:CV_ml_model):\n","    for model in models:\n","      self.ml_models.append(model)\n","      self.trained.append(True)\n","\n","\n","  # 머신러닝 모델 추가\n","  # 훈련안된 머신러닝 모델 함수를 받음\n","  def add_new_ml_models(self, *models):\n","    for model in models:\n","      new_model = CV_ml_model(model, self.X_train, self.Y_train)\n","      self.ml_models.append(new_model)\n","      self.trained.append(False)\n","\n","\n","  # 머신러닝 모델 전체 훈련\n","  # 훈련되어있지 않은 모델만 훈련함\n","  def fit_ml_model(self, n_folds, save = False):\n","    for idx, model in enumerate(self.ml_models):\n","      if (not self.trained[idx]):\n","        model.fit(n_folds, save=save)\n","        self.trained[idx] = True\n","\n","\n","  # class 내에 추가된 머신러닝 모델 전체 불러오기\n","  def load_all_models(self):\n","    for idx, model in enumerate(self.ml_models):\n","      self.trained[idx] = model.load()\n","\n","\n","  # class 내에 추가된 머신러닝 모델 전체 저장\n","  def save_all_models(self):\n","    for model in self.ml_models:\n","      model.save()\n","\n","\n","  # 훈련 여부 수동 체크\n","  def trained_check(self, idx):\n","    self.trained[idx] = True\n","\n","\n","  # 머신러닝 모델 하나 훈련 (파라미터 입력 가능)\n","  def fit_one_ml_model(self, n_folds, model_idx, use_params = False, params = None, save=False):\n","    self.ml_models[model_idx].fit(n_folds, use_params, params, save)\n","    self.trained[model_idx] = True\n","\n","\n","  # 머신러닝 모델 하나 경량 훈련 (파라미터 입력 가능)\n","  def slim_fit_one_ml_model(self, n_folds, model_idx, use_params = False, params = None, save=False):\n","    self.ml_models[model_idx].slim_fit(n_folds, use_params, params, save)\n","    self.trained[model_idx] = True\n","\n","  \n","  # 모델 전체 입력값 예측\n","  def predict_ml_model(self, X_test):\n","    for model in self.ml_models:\n","      model.predict(X_test)\n","\n","  \n","  # 모델 이름 변경\n","  def set_ml_name(self, model_idx, name):\n","    self.ml_models[model_idx].set_name(name)\n","\n","\n","  # 메타 훈련을 위해 해당 Y인덱스만 남기고 훈련\n","  # 훈련되지 않은 모델은 훈련 진행\n","  def meta_fit(self, n_folds):\n","    Y_preds = []\n","\n","    # X_train, Y_train을 통해 학습된 Y_pred를 Y_preds에 추가\n","    for idx, model in enumerate(self.ml_models):\n","      if (not self.trained[idx]):\n","        model.fit(n_folds)\n","        self.trained[idx] = True\n","      Y_preds.append(model.get_train_preds())\n","\n","    Y_preds = np.hstack(Y_preds)\n","\n","    for y_idx in range(14):\n","      print(y_idx, end= ' ')\n","      # y_idx와 동일한 y_pred만을 메타 러닝\n","      X_meta_train = Y_preds[:, [i for i in range(Y_preds.shape[1]) if i % 14 == y_idx]]\n","      super().y_fit(n_folds, y_idx, X_meta_train)\n","\n","    print('Meta', self.name, 'Trained!')\n","\n","\n","  # 학습된 모델을 통해 메타 예측\n","  # meta_fit 선행 필수\n","  def meta_predict(self, X_test):\n","    Y_preds = []\n","    X_test = super().to_np(X_test)\n","\n","    # X_test를 통해 예측된 Y_pred를 Y_preds에 추가\n","    for idx, model in enumerate(self.ml_models):\n","      print(model.name, 'Predict Started!')\n","      model.predict(X_test)\n","      Y_preds.append(model.get_test_preds())\n","\n","    Y_preds = np.hstack(Y_preds)\n","\n","    print('Meta Train Started!')\n","\n","    for y_idx in range(14):\n","      # y_idx와 동일한 y_pred만을 통해 예측\n","      X_meta_test = Y_preds[:, [i for i in range(Y_preds.shape[1]) if i % 14 == y_idx]]\n","      super().y_predict(X_meta_test, y_idx)\n","\n","    return np.hstack(self.test_preds)\n","  \n","  \n","  # 전체 모델에 대한 점수 확인\n","  def scores(self):\n","    scores = {}\n","    for model in self.ml_models:\n","      scores[model.name] = model.score()\n","    return scores"],"metadata":{"id":"_foR0RCqsioD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Stacking ensemble 수행"],"metadata":{"id":"grvYT54mP4V9"}},{"cell_type":"markdown","source":["### 4.3.1 메타 모델 생성"],"metadata":{"id":"mIo6G6mJCRZP"}},{"cell_type":"code","source":["# 메타 모델 생성\n","meta_model = meta_ml_model(Ridge, X_train, Y_train)\n","meta_model.set_name('Meta_Ridge')"],"metadata":{"id":"laWDIpak3s2Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.3.2 메타 모델 내에 기반 모델 추가"],"metadata":{"id":"7lbRgEdDCpr-"}},{"cell_type":"code","source":["# 메타모델 내에 튜닝되지 않은 기반 모델 추가\n","meta_model.add_new_ml_models(\n","  LinearRegression, Ridge, Lasso, ElasticNet, LassoLars,\n","  OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, GradientBoostingRegressor, \n","  HistGradientBoostingRegressor, XGBRegressor, LGBMRegressor, CatBoostRegressor\n","    )"],"metadata":{"id":"tbOB5wqd36F5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메타모델 내에 하이퍼파라미터 튜닝된 기반 모델 추가\n","meta_model.add_new_ml_models(\n","  HistGradientBoostingRegressor, XGBRegressor, LGBMRegressor, CatBoostRegressor\n","    )\n","\n","meta_model.set_ml_name(13, 'HistGradientBoostingRegressor_tune')\n","meta_model.set_ml_name(14, 'XGBRegressor_tune')\n","meta_model.set_ml_name(15, 'LGBMRegressor_tune')\n","meta_model.set_ml_name(16, 'CatBoostRegressor_tune')"],"metadata":{"id":"Y005gE0x72xk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.3.3 학습된 모델을 불러오거나 직접 학습"],"metadata":{"id":"x9yjrS4XP80V"}},{"cell_type":"code","source":["# 학습된 모델 불러오기\n","meta_model.load_all_models()\n","meta_model.load()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVq9v1uaAcID","executionInfo":{"status":"ok","timestamp":1661925659336,"user_tz":-540,"elapsed":17911,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"fe92b14e-d2c5-42ff-8f3f-064bc2e51d00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LinearRegression Loaded!\n","Ridge Loaded!\n","Lasso Loaded!\n","ElasticNet Loaded!\n","LassoLars Loaded!\n","OrthogonalMatchingPursuit Loaded!\n","BayesianRidge Loaded!\n","ARDRegression Loaded!\n","GradientBoostingRegressor Loaded!\n","HistGradientBoostingRegressor Loaded!\n","XGBRegressor Loaded!\n","LGBMRegressor Loaded!\n","CatBoostRegressor Loaded!\n","HistGradientBoostingRegressor_tune Loaded!\n","XGBRegressor_tune Loaded!\n","LGBMRegressor_tune Loaded!\n","CatBoostRegressor_tune Loaded!\n","Meta_Ridge Loaded!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# 학습된 모델을 불러오지 않고 직접 학습하기\n","\n","# GradientBoostingRegressor에 대해 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 8)\n","\n","# HistGradientBoostingRegressor에 대해 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 9)\n","\n","# XGBRegressor에 대해 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 10, True, {'objective': 'reg:squarederror', 'random_state': SEED})\n","\n","# LGBMRegressor에 대해 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 11, True, {'random_state': SEED, 'verbose': -1, 'device': 'gpu'})\n","\n","# CatBoostRegressor에 대해 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 12, True, {'loss_function': 'RMSE', 'logging_level': 'Silent', 'random_state': SEED})\n","\n","# HistGradientBoostingRegressor_tune에 대해 하이퍼파라미터 튜닝된 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 13, True)\n","\n","# XGBRegressor_tune에 대해 하이퍼파라미터 튜닝된 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 14, True)\n","\n","# LGBMRegressor_tune에 대해 하이퍼파라미터 튜닝된 경량화 훈련\n","meta_model.slim_fit_one_ml_model(5, 15, True)\n","\n","# CatBoostRegressor_tune에 대해 하이퍼파라미터 튜닝된 경량화 훈련\n","meta_model.slim_fit_one_ml_model(10, 16, True)\n","\n","# 학습 안된 기반 모델 학습\n","meta_model.fit_ml_model(10)\n","\n","# 기반 모델의 예측 결과를 최종 데이터 세트로 하여 메타 모델 학습\n","meta_model.meta_fit(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JDUcXRgMNWy","executionInfo":{"status":"ok","timestamp":1661920005465,"user_tz":-540,"elapsed":50307,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"a4f6ad3b-5af8-4e4a-ce65-28bed84dc8f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GradientBoostingRegressor Started\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 GradientBoostingRegressor Slim!\n","HistGradientBoostingRegressor Started\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 HistGradientBoostingRegressor Slim!\n","XGBRegressor Started\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 XGBRegressor Slim!\n","LGBMRegressor Started\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 LGBMRegressor Slim!\n","CatBoostRegressor Started\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 CatBoostRegressor Slim!\n","HistGradientBoostingRegressor_tune Started\n","Params Loaded!\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 HistGradientBoostingRegressor_tune Slim!\n","XGBRegressor_tune Started\n","Params Loaded!\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 XGBRegressor_tune Slim!\n","LGBMRegressor_tune Started\n","Params Loaded!\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 LGBMRegressor_tune Slim!\n","CatBoostRegressor_tune Started\n","Params Loaded!\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 CatBoostRegressor_tune Slim!\n","0 1 2 3 4 5 6 7 8 9 10 11 12 13 Meta Meta_Ridge Trained!\n"]}]},{"cell_type":"markdown","source":["# 5 성능 평가"],"metadata":{"id":"s5jxVq1BDI4E"}},{"cell_type":"markdown","source":["메타 모델 내의 기반 모델 별 성능 평가 (Cross-validation)"],"metadata":{"id":"3kFxpd1xGBTH"}},{"cell_type":"code","source":["meta_model.scores()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USXfkfhbWAS8","executionInfo":{"status":"ok","timestamp":1661925659806,"user_tz":-540,"elapsed":490,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"f5cabbe9-edb8-458f-ba14-7e9c5cb60fd5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'LinearRegression': 1.9832964715433596,\n"," 'Ridge': 1.98364582142708,\n"," 'Lasso': 2.011257876889375,\n"," 'ElasticNet': 2.0111884571234477,\n"," 'LassoLars': 2.012444170863825,\n"," 'OrthogonalMatchingPursuit': 1.995407540468963,\n"," 'BayesianRidge': 1.9836601168170116,\n"," 'ARDRegression': 1.9866843993140668,\n"," 'GradientBoostingRegressor': 1.9616975573307935,\n"," 'HistGradientBoostingRegressor': 1.9503053619519914,\n"," 'XGBRegressor': 1.9940671623569788,\n"," 'LGBMRegressor': 1.9487536436470618,\n"," 'CatBoostRegressor': 1.9468092240305752,\n"," 'HistGradientBoostingRegressor_tune': 1.9452303685210361,\n"," 'XGBRegressor_tune': 1.9359791002432554,\n"," 'LGBMRegressor_tune': 1.9385102603433542,\n"," 'CatBoostRegressor_tune': 1.9386097463589151}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["메타 모델 성능 평가 (Cross-validation)"],"metadata":{"id":"dSMA6OSMGN58"}},{"cell_type":"code","source":["meta_model.score()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BUODGtp5Kug","outputId":"796d8cb6-99d7-4238-ce0f-923c910dcf51","executionInfo":{"status":"ok","timestamp":1661925659806,"user_tz":-540,"elapsed":4,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.9321191235308735"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# 6 테스트 데이터 예측"],"metadata":{"id":"gvDKIEOLBpak"}},{"cell_type":"code","source":["test = pd.read_csv(DATA_PATH + 'test.csv').drop(columns=['ID'])"],"metadata":{"id":"QfhLEztiBn1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 영향 없는 인자 제거\n","X_test = test.drop(['X_02', 'X_04', 'X_10', 'X_11', 'X_23', 'X_47', 'X_48'], axis=1)"],"metadata":{"id":"MWp4b3VmCQ0p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PCA 변환\n","X_test = pca_5.transform(X_test)"],"metadata":{"id":"98BXIzmqCZjq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","Y_pred = meta_model.meta_predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SkN-Aq9cCe3F","executionInfo":{"status":"ok","timestamp":1661925799216,"user_tz":-540,"elapsed":138580,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"outputId":"b6057d0a-71bc-4d27-b6cb-6e3b96ba524d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LinearRegression Predict Started!\n","Ridge Predict Started!\n","Lasso Predict Started!\n","ElasticNet Predict Started!\n","LassoLars Predict Started!\n","OrthogonalMatchingPursuit Predict Started!\n","BayesianRidge Predict Started!\n","ARDRegression Predict Started!\n","GradientBoostingRegressor Predict Started!\n","HistGradientBoostingRegressor Predict Started!\n","XGBRegressor Predict Started!\n","LGBMRegressor Predict Started!\n","CatBoostRegressor Predict Started!\n","HistGradientBoostingRegressor_tune Predict Started!\n","XGBRegressor_tune Predict Started!\n","LGBMRegressor_tune Predict Started!\n","CatBoostRegressor_tune Predict Started!\n","Meta Train Started!\n","CPU times: user 2min 32s, sys: 3.48 s, total: 2min 35s\n","Wall time: 2min 18s\n"]}]},{"cell_type":"markdown","metadata":{"id":"ht4QiBdO_F3p"},"source":["## 6.1 CSV 파일로 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AaZdSgastXA"},"outputs":[],"source":["def result(test, name = ''):\n","  submit = pd.read_csv(DATA_PATH +'sample_submission.csv')\n","\n","  for idx, col in enumerate(submit.columns):\n","      if col=='ID':\n","          continue\n","      submit[col] = test[:,idx-1]\n","\n","  submit.to_csv(DATA_PATH + f'submission{name}.csv', index=False)\n","  print('Done.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUl16ZjW_OcR","executionInfo":{"status":"ok","timestamp":1661921965711,"user_tz":-540,"elapsed":1724,"user":{"displayName":"Minseok Kim","userId":"11245162585726491253"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5ed9a42-bf8d-4109-e7f0-c0738d05f8ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Done.\n"]}],"source":["result(Y_pred)"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}